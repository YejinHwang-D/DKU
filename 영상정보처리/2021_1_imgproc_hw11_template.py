# -*- coding: utf-8 -*-
"""2021-1-ImgProc-HW11-Template.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1abCdi5sPPYNf4VqQgoqr41-zLCu1gj2C

## 영상정보처리 11주차 과제 템플리트 
이름: 황예진           
학번: 32195044

# 구글 드라이브 마우팅 및 작업 경로로 이동
- 다음 쉘에 필요한 작업을 하시오.
"""

from google.colab import drive 
drive.mount('/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /gdrive/My Drive/Classroom/[영상정보처리] 2000004793-2021-1/2021-1 영상정보처리 11강/
import matplotlib.pyplot as plt
import numpy as np
import cv2
from skimage.measure import compare_ssim

image_path_airplane = '../Dongkeun-OpenCV-ImgData/airplane_bw.png'
image_path_horse = '../Dongkeun-OpenCV-ImgData/horse_bw.png'

## print function
def show_with_matplotlib(img, title):
  """Shows an image using matplotlib capabilities"""

  #Convert BGR image to RGB:
  img_RGB = img[:,:,::-1]
  
  #Show the image using matplotlib:
  plt.imshow(img_RGB)
  plt.title(title)
  plt.show()

def show_with_matplotlib_gray(img, title):
  plt.imshow(img, cmap="gray")
  plt.title(title)
  plt.show()

def test_same_image_3ch(img1, img2):
  if img1 is None:
    print("test_same_image_3ch: img1 is None")

  if img2 is None:
    print("test_same_image_3ch: img2 is None")

  if img1.shape != img2.shape:
    print("img1.shape = ", img1.shape, " and img2.shape = ", img2.shape, ' are different') 
    return False

  for x in range(0, img1.shape[0]):
    for y in range(0, img1.shape[1]):
      if img1[x,y,0] != img2[x,y,0] or img1[x,y,1] != img2[x,y,1] or img1[x,y,2] != img2[x,y,2]:
        print("Diff pixel", img1[x,y], img2[x,y])
        return False

  return True

# 회선 수행 함수
def filter(image, mask):

    rows, cols = image.shape[:2]
    dst = np.zeros((rows, cols), np.float32)                 # 회선 결과 저장 행렬
    xcenter, ycenter = mask.shape[1] // 2, mask.shape[0] // 2  # 마스크 중심 좌표

    for i in range(ycenter, rows - ycenter):                  # 입력 행렬 반복 순회
        for j in range(xcenter, cols - xcenter):
            y1, y2 = i - ycenter, i + ycenter + 1               # 관심영역 높이 범위
            x1, x2 = j - xcenter, j + xcenter + 1               # 관심영역 너비 범위

            roi = image[y1:y2, x1:x2].astype("float32")         # 관심영역 형변환
            tmp = cv2.multiply(roi, mask)                       # 회선 적용
            dst[i, j] = cv2.sumElems(tmp)[0]                    # 출력화소 저장

    return dst                     # 자료형 변환하여 반환

def differential(image, data1, data2):
    # 입력 인자로 마스크 행렬 초기화
    mask1 = np.array(data1, np.float32).reshape(3, 3)
    mask2 = np.array(data2, np.float32).reshape(3, 3)

    # 사용자 정의 회선 함수
    dst1 = filter(image, mask1)
    dst2 = filter(image, mask2)
    dst = cv2.magnitude(dst1, dst2);  # 회선 결과 두 행렬의 크기 계산

    # dst1, dst2 = np.abs(dst1), np.abs(dst2)  # 회선 결과 행렬 양수 변경
    dst = cv2.convertScaleAbs(dst)
    dst1 = cv2.convertScaleAbs(dst1)
    dst2 = cv2.convertScaleAbs(dst2)
    return dst, dst1, dst2

"""다음 두 개의 이미지에 대해 스켈레톤을 구하는 프로세스를 작성하고, 결과를 가시화하시오.  

입력 이미지 - 이미지 폴더에 없는 경우, 첨부된 이미지를 다운받아 폴더에 넣고 실행하기
- airplane_bw.png
- horse_bw.png
"""

def make_skeleton(img, element, skel_dst):
 while True:
  erode = cv2.erode(img, element)
  opening = cv2.morphologyEx(erode, cv2.MORPH_OPEN, element)
  temp = cv2.subtract(erode, opening)
  skel_dst = cv2.bitwise_or(skel_dst, temp)
  img = erode.copy()
  if cv2.countNonZero(img) == 0:
    break
 show_with_matplotlib_gray(skel_dst, "result image")

image1 = cv2.imread(image_path_airplane, cv2.IMREAD_GRAYSCALE)
image2 = cv2.imread(image_path_horse, cv2.IMREAD_GRAYSCALE)

ret1, th1 = cv2.threshold(image1, 128, 255, cv2.THRESH_BINARY_INV)
ret2, th2 = cv2.threshold(image2, 128, 255, cv2.THRESH_BINARY)

# new image
size1 = np.size(image1)
skel_dst1 = np.zeros(image1.shape, np.uint8)
size2 = np.size(image2)
skel_dst2 = np.zeros(image2.shape, np.uint8)

element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))

show_with_matplotlib_gray(image1, "src")
make_skeleton(th1, element, skel_dst1)

show_with_matplotlib_gray(image2, "src")
make_skeleton(th2, element, skel_dst2)

"""## 문제 2

"2021-1 ImgProc JB-CH07-JHU2104-V1.pdf" 에서 저자 구현 코드와 opencv 함수를 이용하는 방법 둘 다 이용해서 예시를 보여주고 있습니다. 저자 구현 코드와 opencv 를 이용한 방법의 결과를 디스플레이하고, 두 결과를 픽셀 단위로 비교하여 몇 개의 픽셀이 다른 지 계산하고, 픽셀이 다른 경우, 다른 부분만을 영상을 만들어 디스플레이 하시오. 
- 필요한 이미지는 '../Dongkeun-OpenCV-ImgData' 에 복사하여 넣어서 수행
 
1. 예제 7.2.5 (소벨 엣지 검출)
2. 예제 7.2.6 (라플라시안 엣지 검출)
3. 예제 7.2.8 (캐니 엣지 검출)

"""

def compare_image(image1, image2): ## 픽셀 단위 비교 함수
  # 두 이미지를 비교하여 다른 픽셀의 개수 측정하고,
  # 다른 픽셀의 위치를 원본 이미지에서 복사해 새로운 영상 디스플레이
  # 다른 부분이 있을 때 어떤 이미지 값을 출력하는지 이해하지 못하여 원본 이미지로 설정.
  new_image1 = np.zeros(image1.shape, np.uint8)
  diff_count = 0
  for i in range(0,image1.shape[0]):
   for j in range(0,image1.shape[1]):
     if image1[i,j] != image2[i,j]:
       new_image1[i,j] = 255
       diff_count = diff_count + 1
  print("Number of different pixel: ", diff_count)
  show_with_matplotlib_gray(new_image1, "different image")

"""1. 예제 7.2.5 (소벨 엣지 검출)"""

image = cv2.imread("../Dongkeun-OpenCV-ImgData/edge.jpg", cv2.IMREAD_GRAYSCALE)
    
data1 = [-1, 0, 1,                  # 수직 마스크
         -2, 0, 2,
         -1, 0, 1]
data2 = [-1,-2,-1,                 # 수평 마스크
          0, 0, 0,
          1, 2, 1]

dst, dst1, dst2 = differential(image, data1, data2)     # 두 방향 회선 및 크기(에지 강도) 계산
# OpenCV 제공 소벨 에지 계산
dst3 = cv2.Sobel(np.float32(image), cv2.CV_32F, 1, 0, 3)  # x방향 미분 - 수직 마스크
dst4 = cv2.Sobel(np.float32(image), cv2.CV_32F, 0, 1, 3)  # y방향 미분 - 수평 마스크
dst3 = cv2.convertScaleAbs(dst3)                          # 절댓값 및 uint8 형변환
dst4 = cv2.convertScaleAbs(dst4)

show_with_matplotlib_gray(dst, "original image")
show_with_matplotlib_gray(dst1, "dst1")
show_with_matplotlib_gray(dst2, "dst2")
show_with_matplotlib_gray(dst3, "dst3")
show_with_matplotlib_gray(dst4, "dst4")

print(image.shape)
compare_image(image, dst1, dst3)
compare_image(image, dst2, dst4)

"""2. 예제 7.2.6 (라플라시안 엣지 검출)

"""

image = cv2.imread('../Dongkeun-OpenCV-ImgData/laplacian.jpg', cv2.IMREAD_GRAYSCALE)

data1 = [	[0,		1,		0],	# 4 방향 필터
			[1, 	-4,		1],
			[0, 	1,		0]]
data2 = [	[-1,	-1,		-1],	# 8 방향 필터
			[-1, 	8, 	    -1],
			[-1, 	-1, 	-1]]

mask4 = np.array(data1, np.int16)   # 음수가 있으므로 자료형이 int8인 행렬 선언
mask8 = np.array(data2, np.int16)

# OpenCV 함수 cv2.filter2D() 통한 라플라시안 수행
dst1 = cv2.filter2D(image, cv2.CV_16S, mask4)
dst2 = cv2.filter2D(image, cv2.CV_16S, mask8)
dst3 = cv2.Laplacian(image, cv2.CV_16S, 1)      # OpenCV 라플라시안 수행 함수

show_with_matplotlib_gray(image, "original image")
show_with_matplotlib_gray(cv2.convertScaleAbs(dst1), "dst1")
show_with_matplotlib_gray(cv2.convertScaleAbs(dst2), "dst2")
show_with_matplotlib_gray(cv2.convertScaleAbs(dst3), "dst3")

print(image.shape)
compare_image(dst1, dst3)
compare_image(dst2, dst3)

"""3. 예제 7.2.8 (캐니 엣지 검출)"""

def nonmax_suppression(sobel, direct):
    rows, cols = sobel.shape[:2]
    dst = np.zeros((rows, cols), np.float32)
    for i in range(1, rows - 1):
        for j in range(1, cols - 1):
            # 행렬 처리를 통해 이웃 화소 가져오기
            values = sobel[i-1:i+2, j-1:j+2].flatten()
            first = [3, 0, 1, 2]
            id = first[direct[i, j]]
            v1, v2 = values[id], values[8-id]

            dst[i, j] = sobel[i, j] if (v1 < sobel[i , j] > v2) else 0
    return dst

def trace(max_sobel, i, j, low):
    h, w = max_sobel.shape
    if (0 <= i < h and 0 <= j < w) == False: return  # 추적 화소 범위 확인
    if pos_ck[i, j] == 0 and max_sobel[i, j] > low:
        pos_ck[i, j] = 255
        canny[i, j] = 255

        trace(max_sobel, i - 1, j - 1, low)# 추적 함수 재귀 호출 - 8방향 추적
        trace(max_sobel, i    , j - 1, low)
        trace(max_sobel, i + 1, j - 1, low)
        trace(max_sobel, i - 1, j    , low)
        trace(max_sobel, i + 1, j    , low)
        trace(max_sobel, i - 1, j + 1, low)
        trace(max_sobel, i    , j + 1, low)
        trace(max_sobel, i + 1, j + 1, low)

def hysteresis_th(max_sobel, low, high):                # 이력 임계값 수행
    rows, cols = max_sobel.shape[:2]
    for i in range(1, rows - 1):  # 에지 영상 순회
        for j in range(1, cols - 1):
            if max_sobel[i, j] > high:  trace(max_sobel, i, j, low)  # 추적 시작


image = cv2.imread("../Dongkeun-OpenCV-ImgData/canny.jpg", cv2.IMREAD_GRAYSCALE)
pos_ck = np.zeros(image.shape[:2], np.uint8)
canny = np.zeros(image.shape[:2], np.uint8)

# 사용자 정의 캐니 에지
gaus_img = cv2.GaussianBlur(image, (5, 5), 0.3)
Gx = cv2.Sobel(np.float32(gaus_img), cv2.CV_32F, 1, 0, 3)  # x방향 마스크
Gy = cv2.Sobel(np.float32(gaus_img), cv2.CV_32F, 0, 1, 3)  # y방향 마스크
sobel = np.fabs(Gx) + np.fabs(Gy)  # 두 행렬 절댓값 덧셈
# sobel = cv2.magnitude(Gx, Gy)                            # 두 행렬 벡터 크기

directs = cv2.phase(Gx, Gy) / (np.pi / 4)
directs = directs.astype(int) % 4
max_sobel = nonmax_suppression(sobel, directs)   # 비최대치 억제
hysteresis_th(max_sobel, 100, 150)          # 이력 임계값

canny2 = cv2.Canny(image, 100, 150)                 # OpenCV 캐니 에지

show_with_matplotlib_gray(image, "original image")
show_with_matplotlib_gray(canny, "canny")
show_with_matplotlib_gray(canny2, "canny2 OpenCV")

print(image.shape)
compare_image(canny, canny2)